{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fed9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5388095",
   "metadata": {},
   "source": [
    "# Download Dataset and Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2894302",
   "metadata": {},
   "outputs": [],
   "source": [
    "Buffer_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4bb2135",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset,mnist_info = tf_df.load(name='mnist',with_info = True,as_supervised = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd6009ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train,mnist_test = mnist_dataset['train'],mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b8aab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image , label):\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image/=255\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "687d64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c880bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92ae722b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = tf.cast(num_validation_samples,tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b8159c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f23ee469",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validation_data = train_and_validation_data.shuffle(Buffer_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8010fd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_and_validation_data.skip(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad6cb2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "839e03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca15f2bc",
   "metadata": {},
   "source": [
    "# Create the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7531d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers will come one after the other\n",
    "model= tf.keras.Sequential([\n",
    " # first one is the convlution one\n",
    " tf.keras.layers.Conv2D(50,5,activation='relu',input_shape=(28,28,1)),\n",
    " #second one will be MaxPool to compress image\n",
    " tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    " #third one will repeated from first two layers\n",
    " tf.keras.layers.Conv2D(50,3,activation='relu'),\n",
    " tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    " # flatten the result\n",
    " tf.keras.layers.Flatten(),\n",
    " # Dense for the ouput [In this I will use softmax as an activation function]\n",
    " tf.keras.layers.Dense(10)   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c28d5776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d_2 (Conv2D)               (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_3 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten_1 (Flatten)             (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense_1 (Dense)                 (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# showing summary of the model\n",
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58fb9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97ba4663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss = loss_fn,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68cb3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handling overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode = 'auto',\n",
    "    min_delta=0,\n",
    "    patience=2,\n",
    "    verbose=0,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9403383f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 25s - loss: 0.2709 - accuracy: 0.9220 - val_loss: 0.1089 - val_accuracy: 0.9698 - 25s/epoch - 59ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 24s - loss: 0.0720 - accuracy: 0.9788 - val_loss: 0.0655 - val_accuracy: 0.9803 - 24s/epoch - 56ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 24s - loss: 0.0518 - accuracy: 0.9845 - val_loss: 0.0478 - val_accuracy: 0.9845 - 24s/epoch - 56ms/step\n",
      "Epoch 4/20\n",
      "422/422 - 23s - loss: 0.0422 - accuracy: 0.9874 - val_loss: 0.0325 - val_accuracy: 0.9910 - 23s/epoch - 55ms/step\n",
      "Epoch 5/20\n",
      "422/422 - 25s - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.0274 - val_accuracy: 0.9902 - 25s/epoch - 60ms/step\n",
      "Epoch 6/20\n",
      "422/422 - 23s - loss: 0.0311 - accuracy: 0.9900 - val_loss: 0.0261 - val_accuracy: 0.9940 - 23s/epoch - 55ms/step\n",
      "Epoch 7/20\n",
      "422/422 - 24s - loss: 0.0268 - accuracy: 0.9915 - val_loss: 0.0235 - val_accuracy: 0.9942 - 24s/epoch - 56ms/step\n",
      "Epoch 8/20\n",
      "422/422 - 25s - loss: 0.0235 - accuracy: 0.9922 - val_loss: 0.0219 - val_accuracy: 0.9928 - 25s/epoch - 60ms/step\n",
      "Epoch 9/20\n",
      "422/422 - 25s - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.0207 - val_accuracy: 0.9943 - 25s/epoch - 59ms/step\n",
      "Epoch 10/20\n",
      "422/422 - 24s - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.0177 - val_accuracy: 0.9940 - 24s/epoch - 57ms/step\n",
      "Epoch 11/20\n",
      "422/422 - 23s - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.0157 - val_accuracy: 0.9955 - 23s/epoch - 54ms/step\n",
      "Epoch 12/20\n",
      "422/422 - 23s - loss: 0.0153 - accuracy: 0.9953 - val_loss: 0.0122 - val_accuracy: 0.9962 - 23s/epoch - 54ms/step\n",
      "Epoch 13/20\n",
      "422/422 - 23s - loss: 0.0132 - accuracy: 0.9959 - val_loss: 0.0080 - val_accuracy: 0.9972 - 23s/epoch - 53ms/step\n",
      "Epoch 14/20\n",
      "422/422 - 22s - loss: 0.0123 - accuracy: 0.9961 - val_loss: 0.0100 - val_accuracy: 0.9968 - 22s/epoch - 52ms/step\n",
      "Epoch 15/20\n",
      "422/422 - 22s - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0110 - val_accuracy: 0.9963 - 22s/epoch - 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18189484190>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    validation_data = validation_data,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbe635f",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5af383f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - loss: 0.0310 - accuracy: 0.9906\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "test_loss,test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87140d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss :  0.0310. Test accuracy :  99.06%\n"
     ]
    }
   ],
   "source": [
    "# printing the accuracy\n",
    "print('Test loss : {0: .4f}. Test accuracy : {1: .2f}%'.format(test_loss , test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a591d1",
   "metadata": {},
   "source": [
    "# Plotting for images and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d4766d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e1c452ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the test_data into 2 arrays containing the images and the corresponding labels\n",
    "for images , labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "#Reshape the images into 28x28 form , suitable for matplotlib    \n",
    "images_plot = np.reshape(images_test,(10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f05f8ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH4AAAB7CAYAAACy7jQ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAACFElEQVR4nO3dUWqEMBRA0aZ0X+rOdGW6s/R3JjKGVKu83Hv+hlIQLs8QndGUc/4Sz/fTB6BnGB7K8FCGhzI8lOGhfo7+mFJyrxdYzjl9+psTD2V4KMNDGR7K8FCGhzI8lOGhDA9leCjDQxkeyvBQhocyPNTh/Xi68qvny7K8fZ7n+cajuZYTD2V4KE/1L2qn7mEY7jmQGzjxUIaHMjyUa3yDcRyfPoTLOPFQhocyPJRr/Iue9uk1TjyU4aEMD4Ve48t9eW2fXt6WjcyJhzI8lOGhXOOhnHgow0MZHgq9xreK/HXqkhMPZXgow0OlozdU9P5I09rbObZte/s8TdM/Hs31fKSpdgwPZXgo1D6+dR8ebU1v4cRDGR7K8FCofXzrWzVT+rgNDsF9vHYMD2V4KMNDGR7K8FBdX7JtvUTb00+kapx4KMNDGR6qq0u25U+i1nVt+v/ol2hLXrLVjuGhDA/V1T6+9WfPpH17yYmHMjyU4aG6WuNbH0la/kSKxImHMjyU4aFCX6v32vwxr9Vrx/BQhocKvY8nP5L0LCceyvBQhocKvcaffV1Y+b37nh5ZWuPEQxkeyvBQodf4s/t478cLx/BQhocKvca36v3+ewsnHsrwUKFP9Z66/86JhzI8lOGhDA9leCjDQxkeyvBQhocyPJThoQwPZXgow0MZHurwUSjqlxMPZXgow0MZHsrwUIaH+gXlPFcH4K92iAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:1\n"
     ]
    }
   ],
   "source": [
    "# The image to be displayed and tested => Enter any number you want to see\n",
    "i = 10\n",
    "\n",
    "#plot the images\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap=\"gray\", aspect = 'auto')\n",
    "plt.show()\n",
    "\n",
    "print(\"label:{}\".format(labels_test[i - 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4015c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain the model's predictions\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "#convert predictions into probabilities\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# convert probabilities into precentage\n",
    "probabilities = probabilities*100\n",
    "\n",
    "#create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10] , height = probabilities[0],tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
